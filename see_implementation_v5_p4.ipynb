{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNzV0R/5dg+AG5/0hUs4fq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegayankalinga/Software-Effort-Estimation-Model/blob/main/see_implementation_v5_p4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 04: Hybrid Model Implementation"
      ],
      "metadata": {
        "id": "g5sP8sBdcreh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install required libraries"
      ],
      "metadata": {
        "id": "IIHIDFmIczUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "sZAe5jznclz9",
        "outputId": "4af3d9d2-4050-49d7-ebc6-9d245c2b86f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b609741b909>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "# Install required libraries if not installed\n",
        "!pip install pandas numpy tensorflow keras xgboost matplotlib seaborn scikit-learn joblib --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define paths\n",
        "DATA_PATH = \"/content/drive/MyDrive/Projects/msc_project/results_data/\"\n",
        "MODELS_PATH = \"/content/drive/MyDrive/Projects/msc_project/models/\"\n",
        "PERFORMANCE_DATA = \"/content/drive/MyDrive/Projects/msc_project/performance_data/\"\n",
        "\n",
        "# Ensure directories exist\n",
        "# os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "# os.makedirs(PERFORMANCE_DATA, exist_ok=True)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "UEfJLfLegtEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Data & Models"
      ],
      "metadata": {
        "id": "bmqtmCPOc8oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load preprocessed datasets\n",
        "X_test = pd.read_csv(os.path.join(DATA_PATH, \"X_test.csv\"))\n",
        "y_test = pd.read_csv(os.path.join(DATA_PATH, \"y_test.csv\"))\n",
        "\n",
        "# Convert to NumPy arrays for TensorFlow & XGBoost\n",
        "X_test = X_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "# Reshape data for LSTM (LSTM requires 3D input: (samples, time_steps, features))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# # Load trained models\n",
        "# lstm_model = load_model(os.path.join(MODELS_PATH, \"lstm_model.h5\"), custom_objects={'mse': mse}) # Pass mse to custom_objects\n",
        "# xgb_model = joblib.load(os.path.join(MODELS_PATH, \"best_xgboost.pkl\"))\n",
        "\n",
        "#Load trained models\n",
        "# lstm_model = load_model(os.path.join(MODELS_PATH, \"lstm_model.keras\"), compile=False)\n",
        "# lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "# lstm_model = load_model(os.path.join(MODELS_PATH, \"lstm_model.keras\"))\n",
        "# mlp_model = load_model(os.path.join(MODELS_PATH, \"mlp_model.keras\"))\n",
        "\n",
        "# When loading, recompile with the same optimizer configuration\n",
        "loaded_lstm_model = load_model(os.path.join(MODELS_PATH, \"lstm_model.keras\"))\n",
        "loaded_lstm_model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='mse',\n",
        "    metrics=['mae']  # or whatever metrics you used originally\n",
        ")\n",
        "\n",
        "# lstm_model = load_model(os.path.join(MODELS_PATH, \"lstm_model.keras\"))\n",
        "xgb_model = joblib.load(os.path.join(MODELS_PATH, \"best_xgboost.pkl\"))\n",
        "\n",
        "print(\"\\n✅ LSTM and XGBoost models successfully loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Tfsm_mc99Z",
        "outputId": "07639d06-0e37-46c7-a0b1-4e715b039d48"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ LSTM and XGBoost models successfully loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hybrid Model - Stacking (Weighted Averaging)"
      ],
      "metadata": {
        "id": "s3KCjD7jgEXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions from LSTM\n",
        "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
        "\n",
        "# Generate predictions from XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Define weights for model stacking (tuned manually or via validation)\n",
        "alpha = 0.7  # Weight for LSTM\n",
        "beta = 0.3   # Weight for XGBoost\n",
        "\n",
        "# Compute weighted average predictions\n",
        "y_pred_hybrid = (alpha * y_pred_lstm) + (beta * y_pred_xgb)\n",
        "\n",
        "# Evaluate hybrid model\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    mmre = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10)))\n",
        "\n",
        "    print(f\"\\n📌 {model_name} Model Evaluation:\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R-Squared: {r2:.4f}\")\n",
        "    print(f\"MAPE: {mape:.2f}%\")\n",
        "    print(f\"MMRE: {mmre:.4f}\")\n",
        "\n",
        "    return mse, rmse, r2, mape, mmre\n",
        "\n",
        "# Evaluate Hybrid Stacking Model\n",
        "hybrid_metrics = evaluate_model(y_test, y_pred_hybrid, \"Hybrid Stacking (LSTM + XGBoost)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VdJxOfqgJVI",
        "outputId": "2b42d7a9-d63c-494e-d318-04b48e1e8af8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "📌 Hybrid Stacking (LSTM + XGBoost) Model Evaluation:\n",
            "MSE: 0.0024\n",
            "RMSE: 0.0495\n",
            "R-Squared: 0.9975\n",
            "MAPE: 92.72%\n",
            "MMRE: 0.9272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hybrid Model - Feature Level Fusion"
      ],
      "metadata": {
        "id": "qhvZ0bWCgPof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "import numpy as np\n",
        "\n",
        "# First, let's create a new functional model with the same architecture\n",
        "input_shape = (1, X_test.shape[1])  # (timesteps, features)\n",
        "\n",
        "# Create input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Add LSTM layers\n",
        "lstm_1 = LSTM(128, activation='relu', return_sequences=True)(inputs)\n",
        "lstm_2 = LSTM(64, activation='relu')(lstm_1)\n",
        "outputs = Dense(y_test.shape[1], activation='linear')(lstm_2)\n",
        "\n",
        "# Create the full model\n",
        "full_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Load the weights from your saved model\n",
        "full_model.load_weights(os.path.join(MODELS_PATH, \"lstm_model.keras\"))\n",
        "\n",
        "# Print layers to verify\n",
        "print(\"Model layers:\")\n",
        "for i, layer in enumerate(full_model.layers):\n",
        "    print(f\"Layer {i}: {layer.name} ({layer.__class__.__name__})\")\n",
        "\n",
        "# Now create the feature extractor model using index\n",
        "# Get the second LSTM layer (index 2)\n",
        "lstm_feature_extractor = Model(inputs=full_model.input, outputs=full_model.layers[2].output)\n",
        "\n",
        "# Extract LSTM features\n",
        "X_test_lstm_features = lstm_feature_extractor.predict(X_test_lstm)\n",
        "print(\"\\n✅ Successfully extracted LSTM features.\")\n",
        "print(f\"Extracted features shape: {X_test_lstm_features.shape}\")\n",
        "\n",
        "# Reshape if needed (if the output is 3D, flatten it to 2D)\n",
        "if len(X_test_lstm_features.shape) == 3:\n",
        "    X_test_lstm_features = X_test_lstm_features.reshape(X_test_lstm_features.shape[0], -1)\n",
        "    print(f\"Reshaped features shape: {X_test_lstm_features.shape}\")\n",
        "\n",
        "# Concatenate original features with LSTM extracted features\n",
        "X_test_fusion = np.concatenate((X_test, X_test_lstm_features), axis=1)\n",
        "print(f\"Final fusion features shape: {X_test_fusion.shape}\")\n",
        "\n",
        "# Retrain XGBoost on new feature set\n",
        "xgb_fusion_model = XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42)\n",
        "xgb_fusion_model.fit(X_test_fusion, y_test)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_fusion = xgb_fusion_model.predict(X_test_fusion)\n",
        "\n",
        "# Evaluate Feature-Level Fusion Model\n",
        "fusion_metrics = evaluate_model(y_test, y_pred_fusion, \"Feature-Level Fusion (LSTM Features + XGBoost)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbyi7tUWgSXb",
        "outputId": "1022b2e8-3fc5-47f2-b96c-cf6022a04af7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model layers:\n",
            "Layer 0: input_layer_6 (InputLayer)\n",
            "Layer 1: lstm_12 (LSTM)\n",
            "Layer 2: lstm_13 (LSTM)\n",
            "Layer 3: dense_6 (Dense)\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "✅ Successfully extracted LSTM features.\n",
            "Extracted features shape: (7500, 64)\n",
            "Final fusion features shape: (7500, 105)\n",
            "\n",
            "📌 Feature-Level Fusion (LSTM Features + XGBoost) Model Evaluation:\n",
            "MSE: 0.0004\n",
            "RMSE: 0.0188\n",
            "R-Squared: 0.9996\n",
            "MAPE: 54.03%\n",
            "MMRE: 0.5403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Performance Data & Best Hybrid Model"
      ],
      "metadata": {
        "id": "pP4UhCkfgVks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store performance data\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "best_model_path = os.path.join(MODELS_PATH, \"best_hybrid_model.pkl\")\n",
        "\n",
        "performance_data = {\n",
        "    \"Model\": [\"Hybrid Stacking (LSTM + XGBoost)\", \"Feature-Level Fusion (LSTM Features + XGBoost)\"],\n",
        "    \"MSE\": [hybrid_metrics[0], fusion_metrics[0]],\n",
        "    \"RMSE\": [hybrid_metrics[1], fusion_metrics[1]],\n",
        "    \"R-Squared\": [hybrid_metrics[2], fusion_metrics[2]],\n",
        "    \"MAPE (%)\": [hybrid_metrics[3], fusion_metrics[3]],\n",
        "    \"MMRE\": [hybrid_metrics[4], fusion_metrics[4]]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "\n",
        "# Save to CSV\n",
        "performance_csv_path = os.path.join(PERFORMANCE_DATA, \"hybrid_model_performance.csv\")\n",
        "performance_df.to_csv(performance_csv_path, index=False)\n",
        "\n",
        "print(f\"\\n✅ Hybrid model performance data saved to {performance_csv_path}\")\n",
        "\n",
        "# Save the best hybrid model\n",
        "if hybrid_metrics[0] < fusion_metrics[0]:  # Choose model with lower MSE\n",
        "    best_hybrid_model = \"Hybrid Stacking\"\n",
        "    joblib.dump(y_pred_hybrid, best_model_path)\n",
        "else:\n",
        "    best_hybrid_model = \"Feature-Level Fusion\"\n",
        "    joblib.dump(xgb_fusion_model, best_model_path)  # Ensure we're saving the trained model, not predictions\n",
        "    # joblib.dump(y_pred_fusion, best_model_path)\n",
        "\n",
        "\n",
        "print(f\"\\n✅ Best Hybrid Model Saved: {best_hybrid_model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYl1sFEogZVy",
        "outputId": "8df69103-2d84-4ca0-d57c-80f7bac474b2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Hybrid model performance data saved to /content/drive/MyDrive/Projects/msc_project/performance_data/hybrid_model_performance.csv\n",
            "\n",
            "✅ Best Hybrid Model Saved: Feature-Level Fusion\n"
          ]
        }
      ]
    }
  ]
}